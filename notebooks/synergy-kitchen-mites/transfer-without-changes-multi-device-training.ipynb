{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trains using multiple devices, tests on one device**\n",
    "\n",
    "No changes are made to the trained model to facilitate for the target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "%run ../helpers.py\n",
    "\n",
    "dataset_path = '../../datasets/synergy-kitchen-mites-processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_training_dataset_from_multiple_sources**\n",
    "\n",
    "Given y labels and sources, split the y list into N equally sized chunks (N = len(sources)).\n",
    "\n",
    "For each chunk, load its samples from the corresponding source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_training_dataset_from_multiple_sources(sources, y_train, use_features):\n",
    "    training_indices = y_train.index.tolist()\n",
    "    np.random.shuffle(training_indices)\n",
    "\n",
    "    chunk_size = math.floor(len(training_indices) / len(sources))\n",
    "    since = 0\n",
    "    until = chunk_size\n",
    "    \n",
    "    dfs = []\n",
    "    X_trains = []\n",
    "\n",
    "    for source in sources:\n",
    "        if until + chunk_size > len(training_indices):\n",
    "            chunk = training_indices[since:]\n",
    "        else:\n",
    "            chunk = training_indices[since:until]\n",
    "\n",
    "        df = pd.DataFrame.from_csv(dataset_path + source + '.csv')\n",
    "        df = df.filter(regex=(use_features))\n",
    "        df = df.loc[df.id.isin(chunk)]\n",
    "        dfs.append(df)\n",
    "\n",
    "        X_train = pd.DataFrame(index=chunk)\n",
    "        X_trains.append(X_train)\n",
    "\n",
    "        since = until\n",
    "        until += chunk_size\n",
    "\n",
    "    return pd.concat(dfs), pd.concat(X_trains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read labels for the complete dataset\n",
    "2. split them into 70/30 train and test split\n",
    "3. create training dataset using the sources (function above)\n",
    "4. create testing dataset using the 30% of activities from target\n",
    "5. classify and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(sources, target, use_features):\n",
    "    df_labels = pd.DataFrame.from_csv(dataset_path + 'activity_labels.csv')\n",
    "\n",
    "    y_train, y_test = train_test_split_labels(df_labels)\n",
    "\n",
    "    df_train, X_train = create_training_dataset_from_multiple_sources(sources, y_train, use_features)\n",
    "\n",
    "    df_test = pd.DataFrame.from_csv(dataset_path + target + '.csv')\n",
    "    df_test = df_test.filter(regex=(use_features))\n",
    "\n",
    "    X_test = pd.DataFrame(index=y_test.index)\n",
    "\n",
    "    return classify_with_tsfresh_features(df_train, X_train, y_train, df_test, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device_names = {\n",
    "    '128.237.242.0': 'SS008',\n",
    "    '128.237.246.127': 'SS076',\n",
    "    '128.237.248.186': 'SS049',\n",
    "    '128.237.253.157': 'SS018'\n",
    "}\n",
    "\n",
    "devices = [\n",
    "    '128.237.246.127',\n",
    "    '128.237.248.186',\n",
    "    '128.237.253.157',\n",
    "    '128.237.242.0'\n",
    "]\n",
    "\n",
    "combinations = [\n",
    "    [[0,1], 2],\n",
    "#     [[0,1], 3],\n",
    "    [[0,2], 1],\n",
    "    [[0,2], 3],\n",
    "#     [[1,2], 0],\n",
    "    [[1,3], 0],\n",
    "#     [[1,3], 2],\n",
    "#     [[2,3], 0],\n",
    "    [[2,3], 1]\n",
    "]\n",
    "\n",
    "features = {\n",
    "    \"ACCEL_sst_*|id\": 'Accelerometer',\n",
    "    \"MICROPHONE_sst_*|id\": 'Microphone'\n",
    "#     \"MAGNETOMETER_sst_*|id\": 'Magnetometer'\n",
    "}\n",
    "\n",
    "output = []\n",
    "\n",
    "for combination in combinations:\n",
    "    for feature in features:\n",
    "        target = devices[combination[1]]\n",
    "        sources = [devices[i] for i in combination[0]]\n",
    "        result = test(sources, target, feature)\n",
    "        source_names = [device_names[source] for source in sources]\n",
    "        target_name = device_names[target]\n",
    "        feature_name = features[feature]\n",
    "        output.append(feature_name + ' from ' + ', '.join(source_names) + target_name)\n",
    "        output.append(result)\n",
    "\n",
    "for out in output:\n",
    "    print(out)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for out in output:\n",
    "    print (out)\n",
    "    print ('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
