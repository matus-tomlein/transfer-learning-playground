{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giotto/.local/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Dataset configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'synergy-final-iter2'\n",
    "\n",
    "dataset_path = '../datasets/' + dataset + '/'\n",
    "output_path = '../datasets/' + dataset + '-2s-processed/'\n",
    "features_output_path = '../datasets/' + dataset + '-2s-features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devices_to_use = [\n",
    "    '128.237.246.127',\n",
    "    '128.237.248.186',\n",
    "    '128.237.247.134',\n",
    "    '128.237.234.0',\n",
    "    '128.237.237.122',\n",
    "    '128.237.239.234',\n",
    "    '128.237.254.195', # this Mite is only in the Synergy kitchen dataset\n",
    "    'DialogIoT 591844595',\n",
    "    'DialogIoT 591844599',\n",
    "    'DialogIoT 591844765',\n",
    "    'Matrix b827eb96f31a',\n",
    "    'Matrix b827ebe6e0f8',\n",
    "    'Matrix b827eb41f96f',\n",
    "    'TI SensorTag 604',\n",
    "    'TI SensorTag 690',\n",
    "    'TI SensorTag 85',\n",
    "    'xdk_1',\n",
    "    'xdk_2',\n",
    "    'xdk_3',\n",
    "    'TI SensorTag 33',\n",
    "    'TI SensorTag 535',\n",
    "    'TI SensorTag 709'\n",
    "]\n",
    "\n",
    "columns_to_rename = {\n",
    "    'ACCEL_sst_0_avg': 'accel_x',\n",
    "    'ACCEL_sst_1_avg': 'accel_y',\n",
    "    'ACCEL_sst_2_avg': 'accel_z',\n",
    "    'MAGNETOMETER_sst_0_avg': 'mag_x',\n",
    "    'MAGNETOMETER_sst_1_avg': 'mag_y',\n",
    "    'MAGNETOMETER_sst_2_avg': 'mag_z',\n",
    "    'HUMIDITY_sst_0_avg': 'humidity',\n",
    "    'ILLUMINATION_sst_0_avg': 'light',\n",
    "    'BAROMETER_sst_0_avg': 'pressure',\n",
    "    'TEMPERATURE_sst_0_avg': 'temperature',\n",
    "    'MICROPHONE_sst_0_avg': 'microphone',\n",
    "    'MICROPHONE_sst_0_min': 'microphone_min',\n",
    "    'MICROPHONE_sst_0_max': 'microphone_max',\n",
    "    'MICROPHONE_sst_0_sum': 'microphone_sum',\n",
    "    'MICROPHONE_sst_0_variance': 'microphone_variance',\n",
    "    'MICROPHONE_sst_0_range': 'microphone_range',\n",
    "    'MICROPHONE_sst_0_centroid': 'microphone_centroid',\n",
    "    'microphone_avg': 'microphone',\n",
    "    'magnetometer_x': 'mag_x',\n",
    "    'magnetometer_y': 'mag_y',\n",
    "    'magnetometer_z': 'mag_z'\n",
    "}\n",
    "\n",
    "columns_to_keep = '|'.join([\n",
    "    'accel_',\n",
    "    'gyro_',\n",
    "    'mag_',\n",
    "    'humidity',\n",
    "    'light',\n",
    "    'pressure',\n",
    "    'temperature',\n",
    "    'microphone',\n",
    "#     'ACCEL_fft_',\n",
    "#     'MICROPHONE_fft_',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge the individual CSVs into one DataFrame per device for the chosen devices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frames = {}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        device_id = None\n",
    "\n",
    "        for device in devices_to_use:\n",
    "            if file.startswith(device):\n",
    "                device_id = device\n",
    "\n",
    "        if device_id is not None:\n",
    "            df = pd.DataFrame()\n",
    "            if device_id in data_frames:\n",
    "                df = data_frames[device_id]\n",
    "            \n",
    "            df_new = pd.DataFrame.from_csv(dataset_path + file)\n",
    "            df_new.rename(index=str, columns=columns_to_rename, inplace=True)\n",
    "\n",
    "            df_new = df_new.filter(regex=(columns_to_keep))\n",
    "\n",
    "            if len(df_new.columns) > 0:\n",
    "                df = df.join(df_new, how='outer')\n",
    "\n",
    "                data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove duplicate indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert index to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    df = df.ffill().bfill()\n",
    "    data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create 5 sec activity windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_size_secs = 2 # seconds\n",
    "smallest_size_secs = 1 # seconds\n",
    "\n",
    "activities = pd.DataFrame.from_csv(dataset_path + 'activities.csv')\n",
    "labels = pd.DataFrame.from_csv(dataset_path + 'activity_labels.csv')\n",
    "labeled_activities = activities.loc[activities.id != -1]\n",
    "\n",
    "activity_windows = []\n",
    "\n",
    "for id in labeled_activities.id.unique():\n",
    "    start = labeled_activities.loc[labeled_activities.id == id].index.min()\n",
    "    end = labeled_activities.loc[labeled_activities.id == id].index.max()\n",
    "\n",
    "    since = start\n",
    "    until = start + pd.DateOffset(seconds=window_size_secs)\n",
    "\n",
    "    while since < end:\n",
    "        label = labels.loc[id]['label']\n",
    "\n",
    "        length = (until - since).seconds\n",
    "        if length >= smallest_size_secs:\n",
    "            activity_windows.append({\n",
    "                'since': since,\n",
    "                'until': until,\n",
    "                'label': label,\n",
    "                'length': length,\n",
    "                'id': id\n",
    "            })\n",
    "\n",
    "        since = until\n",
    "        until = until + pd.DateOffset(seconds=window_size_secs)\n",
    "        until = min(until, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create per-activity dataframes which are not missing more than 1 second of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 184 removed for TI SensorTag 85, activity 1\n",
      "2 out of 186 removed for DialogIoT 591844595, activity 4\n",
      "1 out of 182 removed for TI SensorTag 604, activity 0\n",
      "1 out of 107 removed for TI SensorTag 604, activity 16\n",
      "69 out of 187 removed for DialogIoT 591844599, activity 8\n",
      "1 out of 196 removed for TI SensorTag 85, activity 5\n",
      "3 out of 184 removed for 128.237.246.127, activity 1\n",
      "2 out of 184 removed for TI SensorTag 604, activity 1\n"
     ]
    }
   ],
   "source": [
    "activity_data_frames = {}\n",
    "device_labels = {}\n",
    "\n",
    "removed_activities = {}\n",
    "all_activities = {}\n",
    "activity_id = 0\n",
    "\n",
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    data_frames[device_id] = None\n",
    "    df['id'] = -1\n",
    "\n",
    "    device_activities = []\n",
    "\n",
    "    for i, window in enumerate(activity_windows):\n",
    "\n",
    "        activity_df = df.loc[df.index >= window['since']]\n",
    "        activity_df = activity_df.loc[activity_df.index <= window['until']].copy()\n",
    "\n",
    "        seconds = activity_df.index.round('s').unique()\n",
    "\n",
    "        key = device_id + ', activity ' + str(window['label'])\n",
    "        if not key in all_activities:\n",
    "            all_activities[key] = 0\n",
    "            removed_activities[key] = 0\n",
    "\n",
    "        if len(seconds) < window['length']:\n",
    "            removed_activities[key] += 1\n",
    "        else:\n",
    "            activity_df['id'] = activity_id\n",
    "            activity_data_frames[activity_id] = activity_df\n",
    "            device_activities.append(pd.DataFrame({\n",
    "                'id': [activity_id],\n",
    "                'label': [window['label']],\n",
    "                'activity_id': [window['id']],\n",
    "                'since': [window['since']],\n",
    "                'until': [window['until']],\n",
    "                'window_id': [i]\n",
    "            }))\n",
    "            activity_id += 1\n",
    "\n",
    "        all_activities[key] += 1\n",
    "\n",
    "    df_labels = pd.concat(device_activities)\n",
    "    df_labels = df_labels.set_index('id')\n",
    "    device_labels[device_id] = df_labels\n",
    "\n",
    "# print stats    \n",
    "for key in all_activities:\n",
    "    if removed_activities[key] > 0:\n",
    "        print(str(removed_activities[key]) + ' out of ' + str(all_activities[key]) + ' removed for ' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resample to 10Hz and fill missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for activity_id in activity_data_frames:\n",
    "    df = activity_data_frames[activity_id]\n",
    "    df = df.resample('100L')\n",
    "    df = df.ffill().bfill()\n",
    "    activity_data_frames[activity_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update device data frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in device_labels:\n",
    "    labels = device_labels[device_id]\n",
    "    df_parts = [activity_data_frames[id] for id in labels.index]\n",
    "    df = pd.concat(df_parts)\n",
    "    data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace timestamp indices with integer ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    df.insert(0, 'i_index', pd.Series(range(len(df.index)), index=df.index))\n",
    "    df = df.set_index(['i_index'])\n",
    "    data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as Pickle files to disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "    df.to_pickle(output_path + device_id + '.p')\n",
    "\n",
    "    df_labels = device_labels[device_id]\n",
    "    df_labels.to_pickle(output_path + device_id + '_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload extracted datasets from disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frames = {}\n",
    "device_labels = {}\n",
    "\n",
    "for root, dirs, files in os.walk(output_path):\n",
    "    for file in files:\n",
    "        device_id = None\n",
    "\n",
    "        for device in devices_to_use:\n",
    "            if file.startswith(device):\n",
    "                device_id = device\n",
    "\n",
    "        if device_id is not None:\n",
    "            df = pd.read_pickle(output_path + file)\n",
    "            if file.endswith('_labels.p'):\n",
    "                device_labels[device_id] = df\n",
    "            else:\n",
    "                data_frames[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Extract features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 18/18 [05:34<00:00,  8.52s/it]\n",
      "WARNING:tsfresh.utilities.dataframe_functions:The columns ['pressure__max_langevin_fixed_point__m_3__r_30'\n",
      " 'pressure__friedrich_coefficients__m_3__r_30__coeff_3'\n",
      " 'pressure__friedrich_coefficients__m_3__r_30__coeff_2'\n",
      " 'pressure__friedrich_coefficients__m_3__r_30__coeff_1'\n",
      " 'pressure__friedrich_coefficients__m_3__r_30__coeff_0'\n",
      " 'temperature__max_langevin_fixed_point__m_3__r_30'\n",
      " 'temperature__friedrich_coefficients__m_3__r_30__coeff_3'\n",
      " 'temperature__friedrich_coefficients__m_3__r_30__coeff_2'\n",
      " 'temperature__friedrich_coefficients__m_3__r_30__coeff_1'\n",
      " 'temperature__friedrich_coefficients__m_3__r_30__coeff_0'] did not have any finite values. Filling with zeros.\n"
     ]
    }
   ],
   "source": [
    "data_frame_features = {}\n",
    "\n",
    "def extract_device_features(df):\n",
    "    extracted_features = extract_features(impute(df), column_id=\"id\")\n",
    "    impute(extracted_features)\n",
    "    return extracted_features\n",
    "\n",
    "for device_id in data_frames:\n",
    "    df = data_frames[device_id]\n",
    "\n",
    "    extracted = extract_device_features(df)\n",
    "    data_frame_features[device_id] = extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort feature columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frame_features:\n",
    "    df = data_frame_features[device_id]\n",
    "    df = df.reindex_axis(sorted(df.columns), axis=1)\n",
    "    data_frame_features[device_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store extracted features on disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frame_features:\n",
    "    extracted = data_frame_features[device_id]\n",
    "    extracted.to_pickle(features_output_path + device_id + '.p')\n",
    "\n",
    "    df_labels = device_labels[device_id]\n",
    "    df_labels.to_pickle(features_output_path + device_id + '_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Do feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_selected = {}\n",
    "\n",
    "for device_id in device_labels:\n",
    "    df = data_frame_features[device_id]\n",
    "    df_labels = device_labels[device_id]\n",
    "    selected = select_features(df, df_labels['label'])\n",
    "    data_frame_selected[device_id] = selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for device_id in data_frame_selected:\n",
    "    selected = data_frame_selected[device_id]\n",
    "    selected.to_pickle(features_output_path + device_id + '_selected.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
